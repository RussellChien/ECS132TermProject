\documentclass[12pt, letterpaper]{report}

\title{\textbf{ECS 132 Term Project}}
\author{\parbox{\linewidth}{\centering%
  Steven Alvarado, Russell Chien, and Ruth Hailu\endgraf\bigskip
  University of California, Davis}}

\usepackage{datetime}
\newdateformat{monthyeardate}{\monthname[\THEMONTH] \THEYEAR}
\date{\monthyeardate\today}

\usepackage{graphicx} 
\usepackage{titlesec}
\usepackage{amsmath}
\usepackage{listings}
\usepackage[usenames,dvipsnames]{color} 

\lstset{ 
  language=R,                    	 	 % The language of the code
  basicstyle=\normalsize\ttfamily,		 % The size of the fonts that are used for the code
  numbers=left,                   		 % Where to put the line-numbers
  numberstyle=\normalsize\color{Blue},  % The style that is used for the line-numbers
  stepnumber=1,                   		 % The step between two line-numbers. If it is 1, each line
                                  			 % will be numbered
  numbersep=5pt,                  		 % How far the line-numbers are from the code
  backgroundcolor=\color{white},  	 % Choose the background color. You must add \usepackage{color}
  showspaces=false,               		 % Show spaces adding particular underscores
  showstringspaces=false,         		 % Underline spaces within strings
  showtabs=false,                 		 % Show tabs within strings adding particular underscores
  frame=single,                   		 % Adds a frame around the code
  rulecolor=\color{black},        		 % If not set, the frame-color may be changed on line-breaks within not-black text (e.g. commens (green here))
  tabsize=2,                      			 % Sets default tabsize to 2 spaces
  captionpos=b,                   		 % Sets the caption-position to bottom
  breaklines=true,                		 % Sets automatic line breaking
  breakatwhitespace=false,        		 % Sets if automatic breaks should only happen at whitespace
  keywordstyle=\color{RoyalBlue},      	 % Keyword style
  commentstyle=\color{YellowGreen},     % Comment style
  stringstyle=\color{ForestGreen}      	 % String literal style
} 

\graphicspath{{plots/}}

\titleformat{\chapter}[display]
  {\normalfont\huge\bfseries\filcenter}{\chaptertitlename\ \thechapter}{20pt}{\Huge}
\titlespacing*{\chapter}
  {0pt}{30pt}{20pt}

\begin{document}
\maketitle

\chapter{The Normal Family}
\section{Communities and Crime: pctWWage}
Our group observed that the variable \textbf{pctWWage} of the Communities and Crime dataset seemed well-approximated by the normal family of continuous distributions.
According to the UCI Machine Learning Repository, \textbf{pctWWage} is described as the percentage of households within the United States with wage or salary income in 1989.

\section{Histogram and Density}
Below are the histogram and density plots of pctWWage using R's hist(), plot(), and density() functions.
\begin{center}
\includegraphics[width=0.45\textwidth]{normal/pctWWage_hist}
\includegraphics[width=0.45\textwidth]{normal/pctWWage_density}
\end{center}


\section{Maximum Likelihood Estimation}
In order to find the MLE of pctWWage, we first had to define our log-likelihood function as
\begin{equation}
  LL(\mu, \sigma^2) = -n \log{(2\pi)} + \frac{\log{(\sigma^2)}}{2} - \frac{\sum(x-\mu)^2}{2\sigma^2}
\end{equation}

Using R's built-in mle() function, we use the \textit{negative} log-likelihood to find the normal parameters of pctWWage.
\begin{lstlisting}
z <- mle(minuslogl = ll, start = c(list(mean = 1), list(var = 1)))
\end{lstlisting} 

Superimposing the resulting density on the kernel estimate plot results in
\begin{center}
\includegraphics[width=0.45\textwidth]{normal/pctWWage_mle}
\end{center}


\section{Method of Moments}
To find the MM-estimated density of pctWWage, we used the following function to approximate $\mu$ and $\sigma^2$.
\begin{lstlisting}
  mm <- function(x) {
    mu <- mean(x)
    sigma <- sqrt(mean(x^2) - mu^2)
    return(c(mu, sigma))
  }  
\end{lstlisting} 

Superimposing the resulting density grants us
\begin{center}
\includegraphics[width=0.45\textwidth]{normal/pctWWage_mm}
\end{center}

\section{Conclusion}
As seen on the plots, the MLE and MM normal approximations appear to be a good fit for pctWWage's data. The density estimates obtained from both methods closely align with the density curve derived directly from the dataset. 
Thus, our group can confidently conclude that the variable pctWWage is well-approximated by the normal distribution family.

\maketitle
\chapter{The Exponential Family}
\section{Communities and Crime: PctLargHouseFam}

For the exponential family of continuous distributions, we observed that the variable \textbf{PctLargHouseFam} was a suitable approximation. 
According to the UCI Machine Learning Repository, \textbf{PctLargHouseFam} is described as the percentage of family households with six or more family members. 

\section{Histogram and Density}


\begin{center}
\includegraphics[width=0.45\textwidth]{exponential/PctLargHouseFam_hist}
\includegraphics[width=0.45\textwidth]{exponential/PctLargHouseFam_density}
\end{center}

\section{MLE and MM}
To find the MLE of the exponential family, we first defined our log likelihood function:
\begin{equation}
  L(\lambda) = n \log{\lambda} - \lambda \sum{x}
\end{equation}
To find the MLE, we use R's built in mle() function with the negative log likelihood function. 
\begin{lstlisting}
  z <- mle(minuslogl = ll, start = c(list(lambda = 1)))
\end{lstlisting} 

\begin{center}
\includegraphics[width=0.45\textwidth]{exponential/PctLargHouseFam_mle}
\end{center}

To find the MM of the exponential family, we used the following function to predict the value of $\lambda$:
\begin{lstlisting}
  mm <- function(x) {
    lambda <- 1 / mean(x)
    lambda
}
\end{lstlisting}

\begin{center}
\includegraphics[width=0.45\textwidth]{exponential/PctLargHouseFam_mm}
\end{center}

\section{Conclusion}
The exponential approximation shows a reasonable fit at the tail end of the density distribution, but it exhibits noticeable deviations from the actual data around \(x=0.2\). The exponential distribution assumes a constant and consistent decay rate, which does not accurately capture the characteristics of the data around its peak.

\maketitle
\chapter{The Gamma Family}
\section{Communities and Crime: PctNotHsGrad}

We observed that the variable \textbf{PctNotHsGrad} of the Communities and Crime dataset seemed well-approximated by the gamma family of continuous distributions.
According to the UCI Machine Learning Repository, \textbf{PctNotHsGrad} is described as the percentage of people 25 and over that are not high school graduates.


\section{Histogram and Density}


\begin{center}
\includegraphics[width=0.45\textwidth]{gamma/PctNotHsGrad_hist}
\includegraphics[width=0.45\textwidth]{gamma/PctNotHsGrad_density}
\end{center}

\section{MLE and MM}
To find the MLE of the gamma family, we first defined our log likelihood function:
\begin{equation}
  L(k, \theta) = (k-1)\sum(\log{x}) - \sum(\frac{x}{\theta}) - n k \log{(\theta)} - n \log{(\Gamma(k))}
\end{equation}
We then had to scale our data to ensure the log likelihood function remained finite: 
\begin{lstlisting}
  x[which(x == 0)] <- 0.0001  
\end{lstlisting} 
To find the MLE, we use R's built in mle() function with the negative log likelihood function. 
\begin{lstlisting}
  z <- mle(minuslogl = ll, start = c(list(k = 1), list(theta = 1)))
\end{lstlisting} 

\begin{center}
\includegraphics[width=0.45\textwidth]{gamma/PctNotHsGrad_mle}
\end{center}

To find the MM of the gamma family, we used the following function to predict the value of $k$ and $\theta$:
\begin{lstlisting}
  mm <- function(x) {
    mu <- mean(x)
    theta <- mean(x * log(x)) - mu * mean(log(x))
    k <- mu / theta
    return(c(k, theta))
}
\end{lstlisting}

\begin{center}
\includegraphics[width=0.45\textwidth]{gamma/PctNotHsGrad_mm}
\end{center}

\section{Conclusion}


\maketitle
\chapter{The Beta Family}
\section{Communities and Crime: PctNotSpeakEnglWell}

For the beta family of continuous distributions, we observed that the variable \textbf{PctNotSpeakEnglWell} was a suitable approximation. 
According to the UCI Machine Learning Repository, \textbf{PctNotSpeakEnglWell} is described as the percentage of people who do not speak English well. 


\section{Histogram and Density}


\begin{center}
\includegraphics[width=0.45\textwidth]{beta/PctNotSpeakEnglWell_hist}
\includegraphics[width=0.45\textwidth]{beta/PctNotSpeakEnglWell_density}
\end{center}


\section{MLE and MM}
To find the MLE of the beta family, we first had to scale our data so it was within the support of $(0, 1)$: 
\begin{lstlisting}
  x[which(x == 0)] <- 0.0001  
  x[which(x == 1)] <- 0.9999
\end{lstlisting} 
We then found the log likelihood function:
\begin{multline}
L(\alpha, \beta) = n \log{(\Gamma(\alpha+\beta))} - n \log{(\Gamma(\alpha))} - n \log{(\Gamma(\beta))} + \\
(\alpha - 1) \sum(\log(x)) + (\beta-1) \sum(\log{(1-x)})
\end{multline}
To find the MLE, we use R's built in mle() function with the negative log likelihood function. 
\begin{lstlisting}
z <- mle(minuslogl = ll, start = c(list(alpha = 1), list(beta = 1)))
\end{lstlisting} 

\begin{center}
\includegraphics[width=0.45\textwidth]{beta/PctNotSpeakEnglWell_mle}
\end{center}

To find the MM of the beta family, we used the following function to estimate the $\alpha$ and $\beta$ values:
\begin{lstlisting}
  mm <- function(x) {
    mu <- mean(x)
    var <- var(x)
    alpha <- mu * (mu * (1 - mu) / var - 1)
    beta <- (1 - mu) * (mu * (1 - mu) / var - 1)
    return(c(alpha, beta))
}
\end{lstlisting} 

\begin{center}
\includegraphics[width=0.45\textwidth]{beta/PctNotSpeakEnglWell_mm}
\end{center}

\section{Conclusion}

\chapter{Contributions}

\end{document}
